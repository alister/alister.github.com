<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Professional Blog]]></title>
  <link href="http://alister.github.com/atom.xml" rel="self"/>
  <link href="http://alister.github.com/"/>
  <updated>2013-01-07T12:40:26+00:00</updated>
  <id>http://alister.github.com/</id>
  <author>
    <name><![CDATA[Alister Bulman]]></name>
    <email><![CDATA[abulman+abgh@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Why I like djbdns & tinydns]]></title>
    <link href="http://alister.github.com/blog/2013/01/07/why-i-like-tinydns/"/>
    <updated>2013-01-07T12:21:00+00:00</updated>
    <id>http://alister.github.com/blog/2013/01/07/why-i-like-tinydns</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been using TinyDNS, and the associated systems, like DNScache and DaemonTools since 2003, when I was first tasked with setting up a local DNS resolver, and a DNS server for a web-development company I was working at <a href="http://www.datasouth.co.uk/">http://www.datasouth.co.uk/</a>. We had dozens of domain names, and organising the changes - as well as paying per domain name, was getting to be, well, annoying, as well as potentially expensive.</p>

<p>So, I was asked to setup our own name servers&#8230;.<!-- more --></p>

<p>I looked at BIND, and even bought the O&#8217;Reilly &#8216;Cricket&#8217; book, but the plan was to use an in-house database management system/CMS to hold the details of the various DNS records and then output the pieces to the DNS server. The thought of producing bind format text files did not appeal - the are pretty complex.</p>

<p>Then, I came across another option - TinyDNS, and a few associated tools, written by djb - Daniel J. Bernstein, who is a mathematician, cryptologist, programmer, and research professor of computer science. It&#8217;s very <em>opinionated</em> software, and so is the configuration, but easy enough to follow a howto and get working.</p>

<p>One of the design choices that make it so easy to work with is that there is a simple-to-understand format for the configuration file, one line per record, for example each Cname, A or MX record is just one line, with the first character being the type (for example a &#8216;@&#8217; for an MX record), and the various parts of it is then split up between colons. The latter parts of the record, with information as time-to-live durations, and other defaults, can be safely left to the defaults.</p>

<p>See: <a href="http://cr.yp.to/djbdns/tinydns-data.html">http://cr.yp.to/djbdns/tinydns-data.html</a> for the exact structure of the data file (or, in fact, of each line that you will generally be using).</p>

<p>Given the various records already in a database, converting them each into such a simple output format is not very difficult at all. In fact, I used an existing perl script as a large basis to do the conversion (porting the perl to PHP was itself trivial), and simply wrapping some database access code around it.</p>

<p>Since the output was just a text file, which was then compiled down into a small database, it was also trivial to have all the name servers (including a tertiary, ns3, name server) call into the server by HTTP (from a cron-job). The web-page produced the data, and output the file as plain text. With the page protected by IP and a HTTP password, it&#8217;s entirely secure, and very easy to setup.</p>

<p>In my next djbdns/tinydns post, I&#8217;ll show you how to setup your own, local top-level domain names - which I find very useful for development, among other things.</p>

<p>Also take a look at the first post in this little series: <a href="http://alister.github.com/blog/2012/12/31/dns-and-my-refreshed-cv-site/">http://alister.github.com/blog/2012/12/31/dns-and-my-refreshed-cv-site/</a>, where I also how an example of a TinyDNS zone file, and how simple it can be made with LuaDNS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[a MySQL optimisation Story]]></title>
    <link href="http://alister.github.com/blog/2013/01/01/a-mysql-day-one-day-freelancing/"/>
    <updated>2013-01-01T17:04:00+00:00</updated>
    <id>http://alister.github.com/blog/2013/01/01/a-mysql-day-one-day-freelancing</id>
    <content type="html"><![CDATA[<p>Here is an example of what a little expertise, judiciously applied can do to speed up larger systems. In this case, take a 30 minute run against a MySQL database down to 5 minutes, or less.</p>

<!-- more -->


<p>Back in Mid-December, I got an email (via LinkedIn) out of the blue from a web development company in Hampshire. They needed some help with a database they were finishing off for a customer. The site itself barely touched the DB, but instead the heavy lifting was being done once per hour to read the data through a somewhat convoluted database view that did a lot of the work of joining various small tables against the main, multi-million row, table.</p>

<p>The regular job was taking around 30 minutes to complete, and then the website then read the results of that to produce the main site pages as required. They wanted to seee how they could speed it up - a lot.</p>

<p>I&#8217;ve dealt with issues like this before, a couple of times in fact, and it had helped me got at least one full-time job in the past because I&#8217;d solved it so easily - stopping the database server crashing a few times a day in the process - so I was happy to take half-hour to talk though the likely scenarios.</p>

<p>It&#8217;s a simple enough problem with MySQL servers. They can handle a lot of work, but they don&#8217;t come with the base configuration to be able to do so. The main issue is having a machine with plenty of memory to handle the amount of data in the database (the sheer megabytes on disk of data), but the <strong>innodb_buffer_pool_size</strong> hasn&#8217;t been updated to be able to use the memory, so all the information has to squeeze though a mere 8MB (yes, not much more than eight million bytes) of space. Not helpful when the database could be measured in Gigabytes.</p>

<p>A couple of days later, I drove down the M3 to visit the office and more efficiently deal with their servers (they were firewalled to only talk to the office IP address), and do some other things.  The database &amp; its slave was already running a lot faster with the increased buffer_pool memory, in fact it had reduced the time to run the production from 30 minutes to just 5, so there was already a huge win for them. Even then, it was still using just 33% of the ram for the DB on the master, and less than 8.5% on the slave.</p>

<p>With a few more small tweaks they&#8217;ve now got plenty of room to grow, and room to easily double the amount of data they are storing in the DB - and they&#8217;ve also had some tips how to be able to run the regularly scheduled cache-run almost as often as the database can be changed, without having to worry about how long it might end up running (something that you would have to be concerned about it you ran it as a cron-job).</p>

<p>What was also done:</p>

<ul>
<li>Removing redundant indexes - they already had columns as part of the first set of a compound index. More indexes is more space, and more time to produce. If the data already has an index that covers the same data - remove it!</li>
<li>Enabling the slow-query log showed a couple of places where a full-text search was still being run, although there was a simple column that could provide the same information.</li>
<li>Reminded them that a string-based UUID as an indexed column was not their friend. The size of the indexes on disk were more than 1.5 times the size of the data!  A simple numeric index would be a fraction of the size, and since that would also mean more data in less space, it would equally mean a faster database.</li>
</ul>


<p>I put the various database tables into individual files, rather than a single, monolithic file (which was over 20GB on disk). While this doesn&#8217;t help with backups, and you also have to increase the number of open_files MySQL has, there are some benefits, such as being able to more easily reclaim space from large database tables. It also means that you can see very easily how much disk space each table takes up, so it can be more easily monitored.</p>

<p>A couple of final things I did was a very quick and easy fix to a PHP-server for a different site. Although the database for the other site was quite small, a quick upgrade of the  <strong>innodb_buffer_pool_size</strong> would help them in the future, but the main improvement I left them with was to install APC with an initial 32MB RAM default. Its a useful and easy speedup for any PHP site. The improvement was pretty obvious to see on-screen, and it would have also used less memory in the process.</p>

<p>So, two websites, with very different needs but both have had substantial improvements in speed. One was entirely back-end and database based, going from a 30 minute turn-around time to regenerate the site from the database to just five minytes, or even less.</p>

<p>The other a more simple PHP site (in fact, written in <a href="http://ellislab.com/expressionengine">Expression Engine</a>). Installing APC produces some very easy improvement in web-page render times.</p>

<p>I hope this has been a useful reminder of how just a little work from a specialist can help your sites can speed up by a great deal.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Booze at tech meetups]]></title>
    <link href="http://alister.github.com/blog/2013/01/01/repost-booze-at-meetups/"/>
    <updated>2013-01-01T10:45:00+00:00</updated>
    <id>http://alister.github.com/blog/2013/01/01/repost-booze-at-meetups</id>
    <content type="html"><![CDATA[<p><a href="http://www.thinkgeek.com/tshirts-apparel/unisex/frustrations/374d/"><img src="http://www.phpscaling.com/wp-content/blogs.dir/6/files/2011/12/lg-go-away-tshirt.jpg" alt="" align="right" /></a>
Originally posted 2011-12-13 at <a href="http://phpscaling.com/2011/12/13/booze-at-meetups/">phpscaling.com</a>.</p>

<p>I was out last night at the <a href="http://lanyrd.com/2011/the-big-xmas-bash/">The Big Xmas Bash</a>, near Silicon Roundabout. It was a fun night out meeting various people, tech, business and recruiters. <strong>Oh, the shame</strong> though - I was wearing the same T-shirt as someone else - and, yes, I have indeed replaced people with small shell scripts.</p>

<p>Now, to the main part of what this post is about - the <strong>rant</strong>.</p>

<!-- more -->


<p>It&#8217;s not aimed at the particular event last night alone though. It&#8217;s alcohol at various tech-meetups in general. Look guys, you generally end up buying too much anyway, and all too often its also to the exclusion of those that may prefer to not get inebriated.</p>

<p>As an example, The <a href="http://lanyrd.com/2011/hn-london-nov/">Hacker News meetups</a> will get dozens of pizzas (which are, admittedly all eaten - there are 150+ people attending usually), but also a couple of stacks worth of cans and bottles, each with 24 cans in each tray, several hundred each at least. It&#8217;s just as well they aren&#8217;t all drunk on the night - many of the event-goers would be unconscious by the end. At least they will also add a few trays of soft-drinks, Lemonade and Cola.</p>

<p>If you want a couple of drinks to help lubricate the social aspect of an evening out, I&#8217;ve got no problem at all. I don&#8217;t though. I prefer to save my brain cells for doing interesting things, like oh, writing code?</p>

<p>For other events, how about adding some more soft drinks to replace some of the alcohol? Last night, the choice was booze, or fizzy water; That was all.</p>

<p>Thankfully, people don&#8217;t generally get blotto at the various meetups - at least that I&#8217;ve seen, but I expect there&#8217;s been one or two that have swerved their way home sometimes.</p>

<p>For the Kernel&#8217;s take on a booze culture in Startup London, see <a href="http://www.kernelmag.com/scene/2792/why-is-east-london-so-goddamn-boozy/">http://www.kernelmag.com/scene/2792/why-is-east-london-so-goddamn-boozy/</a>.</p>

<p><strong>Do you have a comment about alcohol being served at the various meetups?  Would you like more, less, or do you think that organisers and sponsors are doing it right?  I would love to start a conversation here about the good or bad of it.</strong></p>

<p>Comment at <a href="http://phpscaling.com/2011/12/13/booze-at-meetups/">phpscaling.com</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DNS and my refreshed CV site]]></title>
    <link href="http://alister.github.com/blog/2012/12/31/dns-and-my-refreshed-cv-site/"/>
    <updated>2012-12-31T12:07:00+00:00</updated>
    <id>http://alister.github.com/blog/2012/12/31/dns-and-my-refreshed-cv-site</id>
    <content type="html"><![CDATA[<p>It has been in process for a little while, starting when I moved the bulk of my DNS hosting from <a href="http://www.bytemark.co.uk/">http://www.bytemark.co.uk/</a> (with whom I&#8217;ve had a small virtual machine since April 2004). One of the things I really like about Bytemark was the free DNS hosting they provided, particularly since they used <a href="http://tinydns.org/">TinyDNS</a> - which is worthy of its own post. To add a new domain name, create a small file with the relevant lines, with one per DNS record - really easy if you have any kind of database or automation.</p>

<!-- more -->




<div><script src='https://gist.github.com/4419185.js'></script>
<noscript><pre><code># Sample tinydns record
# These records are necessary for each domain to be properly delegate
# to Bytemark's four DNS servers. They insert the necessary NS records
# to claim authority for the domain.
# If you have delegated by name to the [abc].ns.bytemark.co.uk
# servers, use these lines
.abulman.co.uk::a.ns.bytemark.co.uk:259200
.abulman.co.uk::b.ns.bytemark.co.uk:259200
.abulman.co.uk::c.ns.bytemark.co.uk:259200
#
+abulman.co.uk:188.40.84.86:86400
+www.abulman.co.uk:188.40.84.86:86400
+*.abulman.co.uk:188.40.84.86:86400
#
@abulman.co.uk::ASPMX.L.GOOGLE.COM:1:3600
@abulman.co.uk::ALT1.ASPMX.L.GOOGLE.COM:5:3600
@abulman.co.uk::ALT2.ASPMX.L.GOOGLE.COM:5:3600
@abulman.co.uk::ASPMX2.GOOGLEMAIL.COM:10:3600
@abulman.co.uk::ASPMX3.GOOGLEMAIL.COM:10:3600
@abulman.co.uk::ASPMX4.GOOGLEMAIL.COM:10:3600
@abulman.co.uk::ASPMX5.GOOGLEMAIL.COM:10:3600
# SPF record
:abulman.co.uk:16:\037v=spf1\040mx\040include\072plus.net\040~all:86400
# now obsolete link to Livejournal
+journal.abulman.co.uk:204.9.177.18:86400
</code></pre></noscript></div>


<!-- tinydns record -->


<p>Back in April (2012), I came across <a href="http://news.ycombinator.com/item?id=3794654">a post on HackerNews</a> to <a href="http://www.luadns.com/">http://www.luadns.com/</a>. This is a system that again, uses TinyDNS as a backend, but instead of some hacked-together PHP scripts I wrote to produce the data files, they are run through a Lua script. That gives the benefit of very easy to read configurations, and then the files themselves are stored in a Git repository, which can arrange to notify the main luadns website whenever it is changed, so the records are updated whenever the repository is.</p>

<div><script src='https://gist.github.com/4419224.js'></script>
<noscript><pre><code>-- File: abulman.co.uk.lua
-- Zone: abulman.co.uk
-- SOA record is automatically generated
-- Variable _a is replaced with zone name
-- _a = &quot;abulman.co.uk&quot; (from the filename)

-- _webserverIP &amp; _longTTL are variables

-- A records - 
std_a(_a, _webserverIP)
a('blog', _webserverIP, _longTTL)

-- CNAME records
cname(&quot;pages&quot;, 'ghs.google.com')
-- Templates (see templates.lua)
google_app(_a, 'ghs.google.com', _longTTL)
</code></pre></noscript></div>


<!-- luadns record -->


<p>So, with the use of the service from luadns, I had a good reason to a) move my DNS off bytemark (with the intention to also eventually shut down my old server there), and b) tidy it up as I went. So I did. I had already moved my tech-blog to <a href="http://phpscaling.com/">http://phpscaling.com/</a> last year, and over this last few weeks, I added <a href="http://abulman.co.uk/">http://abulman.co.uk/</a> to the same Wordpress installation.</p>

<p>Supporting different domain names for (at least) two different blogs isn&#8217;t too easy in a stack Wordpress 3 installation. It isn&#8217;t made any easier becuase I also have a couple of domain name aliases that point to the <a href="http://abulman.co.uk/">http://abulman.co.uk/</a> site (there is also <a href="http://alisterb.co.uk/">http://alisterb.co.uk/</a>, and of course there is also the www.* versions) and so I was having a lot of trouble till I found the <a href="http://wordpress.org/extend/plugins/wordpress-mu-domain-mapping/">wordpress-mu-domain-mapping</a> plugin. While it&#8217;s not quite a drop-in plugin (you have to copy some files around manually) and of course setup the IP address and domain names, it solved my problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New professional blog]]></title>
    <link href="http://alister.github.com/blog/2012/12/31/new-professional-blog/"/>
    <updated>2012-12-31T11:22:00+00:00</updated>
    <id>http://alister.github.com/blog/2012/12/31/new-professional-blog</id>
    <content type="html"><![CDATA[<p>Welcome. I&#8217;ve taken some time over the holidays to do a little re-organisation of my online presence, and I&#8217;d like to tell you what I did, and how.</p>

<p>First up, is this site. I&#8217;ve been considering what to put onto my Github pages for a while, and I think the most obvious thing are links to my recent work. As it is build on <a href="http://octopress.org/">Octopress/Jekyll</a>,  it is also well supported by Github, and allows me to add static content pages into the site as well, so I&#8217;ve moved my online presentations here, from <a href="http://abulman.co.uk">http://abulman.co.uk</a></p>

<h3>My presentations</h3>

<p>I&#8217;ve done a couple now, both on Queueing systems, and particularly on BeanstalkD, which is a very excellent system for such job-queues.</p>

<ul>
<li><a href="http://alister.github.com/presentations/Beanstalkd/">Beanstalkd</a> PHP London, May 6th 2010</li>
<li><a href="http://alister.github.com/presentations/QueueGoodBad/">Queuing, the good and bad</a> London Scalability Group, 16th July 2012</li>
</ul>


<p>You should also check out my other post, which I also wrote today, <a href="http://alister.github.com/blog/2012/12/31/dns-and-my-refreshed-cv-site/">DNS and my refreshed CV site</a></p>

<h3>My other professional links</h3>

<ul>
<li><a href="http://abulman.co.uk/">http://abulman.co.uk/</a></li>
<li><a href="http://careers.stackoverflow.com/alister">http://careers.stackoverflow.com/alister</a></li>
<li><a href="http://phpscaling.com/">http://phpscaling.com/</a> (technical blog)</li>
<li><a href="https://github.com/alister/">https://github.com/alister/</a> (public projects, Puppet and PHP)</li>
<li><a href="http://lanyrd.com/people/alister_b/">http://lanyrd.com/people/alister_b/</a></li>
<li><a href="http://www.linkedin.com/in/alisterbulman">http://www.linkedin.com/in/alisterbulman</a></li>
<li><a href="http://stackoverflow.com/users/6216/alister-bulman">http://stackoverflow.com/users/6216/alister-bulman</a></li>
<li><a href="http://serverfault.com/users/181/alister-bulman">http://serverfault.com/users/181/alister-bulman</a></li>
<li><a href="http://superuser.com/users/1512/alister-bulman">http://superuser.com/users/1512/alister-bulman</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
